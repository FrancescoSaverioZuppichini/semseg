{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Allow auto-reload of external modules \n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import scipy as scp\n",
    "import scipy.misc\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import nn\n",
    "from network.fcn_instance import InstanceFCN8s\n",
    "import data_utils as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 2.0] [1.0, 2.0, 4.0, 3.0, 6.0]\n",
      "[1.0, 2.0] [1.0, 2.0, 3.0, 4.0, 6.0]\n",
      "[1.0, 2.0] [1.0, 2.0, 4.0, 3.0, 6.0]\n",
      "[1.0, 2.0] [1.0, 2.0, 4.0, 3.0, 5.0, 6.0]\n",
      "[1.0, 2.0] [1.0, 2.0, 4.0, 3.0, 6.0]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "def load_image(fname):\n",
    "    \"\"\"\n",
    "    Load input image and preprocess for using pretrained weight from Caffee:\n",
    "    - cast to float\n",
    "    - switch channels RGB -> BGR\n",
    "    - subtract mean\n",
    "    - transpose to channel x height x width order\n",
    "    \"\"\"\n",
    "    #print('Loading img:%s'%fname)\n",
    "    try:\n",
    "        img = Image.open(fname)\n",
    "    except IOError as e:\n",
    "        print('Warning: no image with name %s!!'%fname)\n",
    "\n",
    "    image = np.array(img, dtype=np.float32)\n",
    "    #image = image[:,:,::-1]     # RGB -> BGR\n",
    "    return image\n",
    "\n",
    "fd = '10000_20'\n",
    "for k in range(5):\n",
    "    x = load_image('data/test_city_instance/%s/person_%d.png'%(fd,k))\n",
    "    (x0,x1) = np.where(x > 0)\n",
    "    pid = []\n",
    "    for i in range(x0.shape[0]):\n",
    "        id = x[x0[i],x1[i]]\n",
    "        if id not in pid:\n",
    "            pid.append(id)\n",
    "\n",
    "    x = load_image('data/test_city_instance/%s/car_%d.png'%(fd,k))\n",
    "    (x0,x1) = np.where(x > 0)\n",
    "    cid = []\n",
    "    for i in range(x0.shape[0]):\n",
    "        id = x[x0[i],x1[i]]\n",
    "        if id not in cid:\n",
    "            cid.append(id)\n",
    "\n",
    "    print(pid, cid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 4.0, 5.0, 3.0, 2.0, 6.0, 7.0, 15.0]\n"
     ]
    }
   ],
   "source": [
    "(x0,x1) = np.where(x > 0)\n",
    "ids = []\n",
    "for i in range(x0.shape[0]):\n",
    "    id = x[x0[i],x1[i]]\n",
    "    if id not in ids:\n",
    "        ids.append(id)\n",
    "\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load train dataset\n",
      "Loading masks\n",
      "Training images:0 Ground Truth images:0\n",
      "Running the inference ...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-33320fb132de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# Load data, Already converted to BGR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mnext_pair\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mnext_pair_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         train_feed_dict = {train_img: next_pair_image,\n",
      "\u001b[0;32m/Users/jennyzhou/GitLocalRepository/APC_InstanceSegmentation/core/dataset/CityDataSet.py\u001b[0m in \u001b[0;36mnext_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mimg_fname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0;31m#print('Batch index: %d'%self.idx)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Testing script for fcn32 without skip architecture.\n",
    "'''\n",
    "from scipy.misc import toimage\n",
    "from scipy.misc import imsave\n",
    "\n",
    "def get_gtmask_tuple(gt_sparse, inst_id):\n",
    "    '''\n",
    "    gt_sparse: [1, H, W, 1] sparse gt mask\n",
    "    inst_id: 1-30 (MUST not start from 0!)\n",
    "    Return: tuple (0/1 mask, #1s)\n",
    "    '''\n",
    "    gt_shape = tf.shape(gt_sparse)\n",
    "    gt_sparse = tf.reshape(gt_sparse, [gt_shape[1], gt_shape[2], 1])\n",
    "    where = tf.equal(gt_sparse, inst_id)\n",
    "    indices = tf.where(where)\n",
    "    val = tf.ones((tf.shape(indices)[0],),tf.float32)\n",
    "    mask = tf.sparse_to_dense(indices,[1024, 2048,1],val)\n",
    "    mask = tf.reshape(mask, [1, 1024, 2048, 1])\n",
    "\n",
    "    return (mask, tf.shape(indices)[0])\n",
    "\n",
    "\n",
    "# Import training and validation dataset\n",
    "test_data_config = {'city_dir':\"../data/CityDatabase\",\n",
    "                     'randomize': False,\n",
    "                     'use_gt_mask': True,\n",
    "                     'seed': None,\n",
    "                     'dataset':'train'\n",
    "                     }\n",
    "params = {'num_classes': 20, 'max_instance': 20, \n",
    "          'target_class':{11:'person', 13:'car'},\n",
    "          'trained_weight_path':'../data/val_weights/city_instance_100.npy'}\n",
    "\n",
    "test_dataset = dt.CityDataSet(test_data_config)\n",
    "iterations = 1\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialization\n",
    "    image = tf.placeholder(tf.float32, shape=[1, None, None, 3])\n",
    "    train_gt_mask = tf.placeholder(tf.int32, shape=[1, None, None, len(params['target_class'])])\n",
    "    gt_mask_list = tf.split(3, 2, train_gt_mask)\n",
    "    total_pixel = 1024 * 2048\n",
    "    gt_list = []\n",
    "\n",
    "    for i in range(2):\n",
    "        gt = gt_mask_list[i]\n",
    "        for j in range(params['max_instance']):\n",
    "            (gt_j, inst_pixel) = get_gtmask_tuple(gt, j+1)\n",
    "            weight = tf.cond(tf.equal(inst_pixel, 0), lambda: tf.constant(1, dtype=tf.float64) , lambda: (total_pixel - inst_pixel) / inst_pixel )\n",
    "            weight = tf.cast(weight, tf.float32)\n",
    "            gt_j = tf.cast(gt_j, tf.float32)\n",
    "            gt_list.append(gt_j)\n",
    "    \n",
    "    init = tf.initialize_all_variables()\n",
    "    sess.run(init)\n",
    "\n",
    "    for i in range(iterations):\n",
    "        # Load data, Already converted to BGR\n",
    "        next_pair = test_dataset.next_batch()\n",
    "        next_pair_image = next_pair[0]\n",
    "        train_feed_dict = {train_img: next_pair_image,\n",
    "                           train_gt_mask: next_pair_gt_mask,}\n",
    "\n",
    "        gt_list_ = sess.run(gt_list, feed_dict=train_feed_dict)\n",
    "#         pname = '../data/test_city_instance/person_%d.png'%i\n",
    "#         cname = '../data/test_city_instance/car_%d.png'%i\n",
    "#         toimage(predict_[0], high=params['max_instance'], low=0, cmin=0, cmax=params['max_instance']).save(pname)\n",
    "#         toimage(predict_[1], high=params['max_instance'], low=0, cmin=0, cmax=params['max_instance']).save(cname)\n",
    "        \n",
    "        #imsave('../data/test_city_instance/person_%d.png'%i,predict_[0])\n",
    "        #imsave('../data/test_city_instance/car_%d.png'%i, predict_[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.random.rand(1,4,4,3)\n",
    "w = tf.Variable(x)\n",
    "k = tf.Variable(np.random.rand(3,3,2,5))\n",
    "lis = [0,2]\n",
    "lis_ = []\n",
    "for i in lis:\n",
    "    t = tf.slice(w, [0,0, 0, i], [1,4, 4, 1])\n",
    "    lis_.append(t)\n",
    "new = tf.concat(3,lis_)\n",
    "conv = tf.nn.depthwise_conv2d(new, k,\n",
    "                              strides=[1, 1, 1, 1],\n",
    "                              padding='SAME')\n",
    "\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    m = sess.run(new)\n",
    "    c = sess.run(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4, 4, 2)\n",
      "(1, 4, 4, 10)\n"
     ]
    }
   ],
   "source": [
    "print(m.shape)\n",
    "print(c.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load weight file from /Users/jennyzhou/GitLocalRepository/APC_InstanceSegmentation/core/data/vgg16.npy.\n"
     ]
    }
   ],
   "source": [
    "data_dict = dt.load_weight('data/vgg16.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 512, 512) (512,)\n",
      "(25088, 4096) (4096,)\n",
      "(3, 3, 512, 512) (512,)\n",
      "(4096, 4096) (4096,)\n",
      "(4096, 1000) (1000,)\n",
      "(3, 3, 512, 512) (512,)\n",
      "(3, 3, 256, 512) (512,)\n",
      "(3, 3, 512, 512) (512,)\n",
      "(3, 3, 512, 512) (512,)\n",
      "(3, 3, 256, 256) (256,)\n",
      "(3, 3, 256, 256) (256,)\n",
      "(3, 3, 128, 256) (256,)\n",
      "(3, 3, 3, 64) (64,)\n",
      "(3, 3, 64, 64) (64,)\n",
      "(3, 3, 128, 128) (128,)\n",
      "(3, 3, 64, 128) (128,)\n"
     ]
    }
   ],
   "source": [
    "for x in data_dict:\n",
    "    print(data_dict[x][0].shape, data_dict[x][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
